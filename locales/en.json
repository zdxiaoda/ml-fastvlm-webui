{
  "title": "FastVLM - Visual Language Model Interface",
  "desc": "Upload an image and enter a prompt, and the model will generate a description or answer questions about the image.",
  "main_interface_tab_label": "Main Interface",
  "select_model_to_download": "Select Model to Download",
  "download_model_button": "Download Model",
  "download_status_label": "Download Status",
  "download_progress": "Download Progress: {progress}% ({model_name})",
  "select_model": "Select Loaded Model",
  "unload_model_button": "Unload Current Model",
  "model_load_unload_status_label": "Model Status",
  "upload_image": "Upload Image",
  "prompt_label": "Prompt",
  "default_prompt": "Describe this image.",
  "adv_params": "Advanced Parameters",
  "temperature": "Temperature",
  "top_p": "Top P",
  "top_p_info": "If set to < 1, only the smallest set of most probable tokens with probabilities that add up to top_p or higher are kept for generation.",
  "num_beams": "Number of Beams",
  "conv_mode": "Conversation Mode",
  "submit": "Submit",
  "output": "Output",
  "lang_label": "Language",
  "lang_en": "English",
  "lang_zh": "Chinese",
  "lang_display_name": "English",
  "model_unloaded_success": "Model unloaded successfully.",
  "model_switched": "Switched to model: {model_path}",
  "error_model_not_init": "Error: Model components not fully initialized. Please check server logs and restart.",
  "error_no_image": "Error: Please input an image.",
  "error_no_prompt": "Error: Please input a prompt.",
  "error_invalid_conv": "Error: Invalid conversation mode '{conv_mode}'. Available modes: {modes}",
  "error_tokenize": "Error: Tokenization failed - {err}",
  "error_image_proc": "Error: Image processing failed - {err}",
  "error_infer": "Error: Model inference error - {err}",
  "error_invalid_model_path_selected": "Error: Selected model path '{path}' is invalid.",
  "error_model_load_failed": "Error: Failed to load model {model_path}.",
  "error_no_model_found_or_downloadable": "Error: No local models found and no models available for download. Please check your model configuration.",
  "error_no_model_found": "No model folders found in the 'model' directory. Please download a model first.",
  "load_model_button": "Load Model",
  "model_loaded_success": "Model {model_path} loaded successfully.",
  "download_error": "Download Error ({model_name}): {error}",
  "download_starting": "Starting download of model {model_name}...",
  "download_detailed_progress": "Downloading {model_name}: {downloaded_mb:.2f}MB / {total_mb:.2f}MB ({speed_mbps:.2f} MB/s)",
  "created_model_dir": "Created model directory: {dir}",
  "unzip_starting": "Starting to extract file: {file}...",
  "unzip_complete": "Extraction complete, model {model_name} saved to: {dir}",
  "zip_removed": "Cleaned up downloaded zip file: {file}",
  "model_download_success_with_path": "Model {model_name} downloaded successfully, saved to: {path}",
  "model_download_success_no_path": "Model {model_name} downloaded successfully, but its exact path could not be automatically determined in the list. Please check the model selector.",
  "download_queued": "Model {model_name} has been queued for download...",

  "api_settings_tab_label": "API Settings",
  "api_settings_desc": "Configure and manage the API server settings for integration with other applications.",
  "api_host_label": "API Host",
  "api_port_label": "API Port",
  "start_api_button": "Start API Server",
  "stop_api_button": "Stop API Server",
  "api_status_label": "API Status",
  "api_not_started_status": "API server not started.",
  "error_invalid_port": "Invalid port number: {port}. Error: {error}"
}
